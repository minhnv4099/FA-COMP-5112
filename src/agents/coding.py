#
#  Copyright (c) 2025
#  Minh NGUYEN <vnguyen9@lakeheadu.ca>
#
import logging
import os
from typing import Optional, Union

from langchain_core.language_models import BaseChatModel
from langchain_core.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)
from langgraph.config import RunnableConfig
from langgraph.graph.state import END
from langgraph.runtime import Runtime
from langgraph.types import Command
from typing_extensions import override, Any

from src.base.agent import AgentAsNode, InputT, register
from src.base.exception import NotCompletedError, ScriptWithError
from src.base.tool import execute_script, write_script

logger = logging.getLogger(__name__)


@register(type="agent", name='coding')
class CodingAgent(AgentAsNode, name='Coding', use_model=True):
    """
    The Coding Agent class
    """

    @override
    def __init__(
            self,
            metadata: dict = None,
            input_schema: InputT = None,
            edges: dict[str, tuple[str]] = None,
            tool_schemas: list = None,
            output_schema: Any = None,
            model_name: str = None,
            model_provider: str = None,
            model_api_key: str = None,
            output_schema_as_tool: bool = None,
            chat_model: BaseChatModel = None,
            anchor_folder: str = None,
            system_prompt: str = None,
            human_prompt: str = None,
            fix_error_attempts: int = 5,
            **kwargs
    ):
        super().__init__(
            metadata,
            input_schema,
            edges,
            tool_schemas,
            output_schema,
            model_name,
            model_provider,
            model_api_key,
            output_schema_as_tool,
            chat_model,
            **kwargs
        )

        self.anchor_folder = anchor_folder
        """Anchor folder containing scripts generated by model each attempt"""

        self.system_prompt = SystemMessagePromptTemplate.from_template("""
            You're smart assistance and able to generate Python code in Blender
            Your mission are:
                1. Base on given scripts (if available), "query/subtask " and given "docs" to generate code.

            The format looks like:
            ```JSON block
                subtask: <subtask> 
                docs: [<docs>]
                previous: [<previous_code>]
            """)

        self.human_generate_code_prompt = HumanMessagePromptTemplate.from_template("""
        Help me to write python code using below information:
            subtask: {subtask}
            docs: {docs} 
            previous: {previous_code}
            
        With following instructions:
            - Not include 'bmesh' module
            - Delete all materials before writing by import 2 lines after import libraries
                ```
                    bpy.ops.object.select_all(action='SELECT')
                    bpy.ops.object.delete(use_global=False)
                ```
        """)

        self.human_apply_improvements_prompt = HumanMessagePromptTemplate.from_template("""""")
        self.human_fix_error_prompt = HumanMessagePromptTemplate.from_template("""""")

        self.fix_error_attempts = fix_error_attempts
        self.fix_error_tries = 0
        self.subtask_offset = 0

    @override
    def __call__(
            self,
            state: InputT | dict,
            runtime: Optional[Runtime] = None,
            context: Optional[Runtime] = None,
            config: Optional[Runtime[RunnableConfig]] = None,
            **kwargs
    ) -> Union[dict, Command]:
        # --------------- model works ---------------
        # logger.info(f"coding {self.subtask_offset} \n\t {state}", )
        self.subtask_offset += 1
        if not state['has_docs']:
            return Command(
                goto='retriever',
                update={
                    'coding_task': state['coding_task'],
                    'queries': state['queries']
                },
            )
        try:
            if state['coding_task'] == 'generate':
                script = self._generate_script(state, context)
            elif state['coding_task'] == "improve":
                script = self._apply_improvements(state, context)
            else:
                script = self._fix_error(state, context)
        # -------------------------------------------
        except ScriptWithError as e:
            """Recall Coding Agent if catch command when executing script
            Before fix code, call Retriever Agent to get relevant documents
            `e.command` is a command call retriever with command and command script
            """
            return e.command

        return Command(
            update={'current_script': script},
            goto=END
        )

    def _prepare_by_adding_human_prompt(self, human_prompt):
        return ChatPromptTemplate([
            self.system_prompt,
            human_prompt,
        ])

    def _fix_error(self, state, context) -> str:
        chat_prompt = self._prepare_by_adding_human_prompt(self.human_fix_error_prompt)

        formatted_prompt = chat_prompt.invoke({
            'script': state['current_script'],
            'command': state['queries'],
            'docs': state['retrieved_docs']
        })

        # ---------------------------------------------------
        fixed_script = self._write_code(formatted_prompt, context)
        # ---------------------------------------------------

        return fixed_script

    def _apply_improvements(self, state, context):
        raise NotCompletedError

        chat_prompt = ChatPromptTemplate([
            self.system_prompt,
            self.human_apply_improvements_prompt,
        ])

        formatted_prompt = chat_prompt.invoke({
            'script': state['current_script'],
            'improvements': state['queries'],
            'docs': state['retrieved_docs'],
        })
        # ---------------------------------------------------
        improved_script = self._write_code(formatted_prompt, context)
        # ---------------------------------------------------
        return improved_script

    def _generate_script(self, state, context):
        chat_prompt = ChatPromptTemplate([
            self.system_prompt,
            self.human_generate_code_prompt,
        ])
        subscripts = []
        for i, query in enumerate(state['queries']):
            docs = state['retrieved_docs'][i]

            # -----------precess docs -----------
            # here
            # -----------------------------------

            formatted_prompt = chat_prompt.invoke({
                "subtask": query,
                "docs": docs,
                "previous_code": subscripts,
            })
            # ---------------------------------------------------
            message = self._write_code(formatted_prompt, context)
            # ---------------------------------------------------
            subscripts.append(message)
        return subscripts[-1]

    def _write_code(self, formatted_prompt, context):
        while True:
            generated_script = self._stimulate_model_invoke()
            anchor_file = os.path.join(self.anchor_folder, f"fake_script.py")
            write_script.invoke({
                "script": generated_script,
                "file_path": anchor_file
            })
            result = execute_script.invoke(input={"script": anchor_file})
            error = result['error']

            if len(error) == 0 or self.fix_error_tries == self.fix_error_attempts:
                # Test script would be fixed successfully
                generated_script = 'import sys'
                return generated_script
            else:
                self.fix_error_tries += 1
                raise ScriptWithError(command=Command(
                    goto='retriever',
                    update={
                        'coding_task': 'fix',
                        'queries': [error, ],
                        'current_script': generated_script
                    },
                ))

    def _stimulate_model_invoke(self):
        return "import os pri"

    def _chat_model_invoke(self, formatted_prompt, context):
        response = self.chat_model.invoke(formatted_prompt)
        try:
            generated_script = response.tool_calls[-1]['args']['script']
        except KeyError as e:
            exit()

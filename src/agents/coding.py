#
#  Copyright (c) 2025
#  Minh NGUYEN <vnguyen9@lakeheadu.ca>
#
import logging
import os
from copy import deepcopy
from typing import Union

from langchain_core.language_models import BaseChatModel
from langchain_core.prompts import ChatPromptTemplate
from langgraph.config import RunnableConfig
from langgraph.types import Command, Send
from typing_extensions import override, Any

from ..base.agent import AgentAsNode
from ..base.mapping import register
from ..base.tool import execute_script, write_script
from ..base.utils import DirectionRouter
from ..utils import ScriptWithError, InputT, load_prompt_template_file

logger = logging.getLogger(__name__)


@register(type="agent", name='coding')
class CodingAgent(AgentAsNode, name='Coding', use_model=True):
    """
    The Coding Agent class
    """

    @override
    def __init__(
            self,
            metadata: dict = None,
            input_schema: InputT = None,
            edges: dict[str, tuple[str]] = None,
            tool_schemas: list = None,
            output_schema: Any = None,
            model_name: str = None,
            model_provider: str = None,
            model_api_key: str = None,
            output_schema_as_tool: bool = None,
            chat_model: BaseChatModel = None,
            anchor_folder: str = None,
            # templates
            template_file: str = None,
            fix_error_attempts: int = None,
            **kwargs
    ):
        super().__init__(
            metadata=metadata,
            input_schema=input_schema,
            edges=edges,
            tool_schemas=tool_schemas,
            output_schema=output_schema,
            model_name=model_name,
            model_provider=model_provider,
            model_api_key=model_api_key,
            output_schema_as_tool=output_schema_as_tool,
            chat_model=chat_model,
            template_file=template_file,
            **kwargs
        )

        self.anchor_folder = anchor_folder
        """Anchor folder containing scripts generated by each attempt"""

        template_dict = load_prompt_template_file(self.template_file)

        self.system_template = template_dict['system_template']

        self.human_generate_template = template_dict['human_generate_template']
        self.human_fix_template = template_dict['human_fix_template']
        self.human_improve_template = template_dict['human_improve_template']

        self.fix_error_attempts = fix_error_attempts
        self.fix_error_tries = 0

        self.copy_state = dict()

    @override
    def __call__(
            self,
            state: InputT | dict,
            runtime: RunnableConfig = None,
            context: RunnableConfig = None,
            config: RunnableConfig = None,
            **kwargs
    ) -> Union[dict, Command, Send, None]:
        # ----------------------------------------
        # This block is always executed only one time
        # store state from the official call
        if not state['is_sub_call']:
            self.copy_state = deepcopy(state)
            self.copy_state.pop('is_sub_call', None)
            self.copy_state.pop('has_docs', None)
            self.copy_state['num_queries'] = len(state['queries'])
            self.copy_state['query_offset'] = 0
            self.copy_state['previous_scripts'] = []
            self.get_retrieved_docs = False

        if not state['has_docs']:
            return DirectionRouter.goto(state={
                'coding_task': state['coding_task'],
                'queries': state['queries']
            }, node='retriever', method='send')
        # store retrieved docs of first queries (official call)
        if not self.get_retrieved_docs:
            self.copy_state['retrieved_docs'] = state['retrieved_docs']
            self.get_retrieved_docs = True
        # later call this agent must pass above
        # ----------------------------------------

        # operate on each query
        try:
            if state['coding_task'] == 'generate':
                script = self._generate_script(state)
            elif state['coding_task'] == "improve":
                assert 'current_script' in state
                script = self._apply_improvements(state)
            else:
                assert 'current_script' in state
                script = self._fix_error(state)

            # when the generated script is error-free,
            # it is also an ending point for recursive calls
            self.copy_state['previous_scripts'].append(script)
            self.copy_state['current_script'] = script
            self.copy_state['query_offset'] += 1

        except ScriptWithError as e:
            self.fix_error_tries += 1
            """Recall Coding Agent if catch command when executing script
            Before fix code, call Retriever Agent to get relevant documents
            `e.command` is a command call retriever with command and command script
            """
            return e.command

        # return original state stored at the beginning
        # as there may be some sub calls from `retriever` that may change state

        if self.copy_state['query_offset'] < self.copy_state['num_queries']:
            # Continue with the next query
            self.fix_error_tries = 0
            next_node = 'coding'
        else:
            # move on to another node if all queries are solved
            if self.copy_state['caller'] == 'planner':
                next_node = 'critic'
            elif self.copy_state['caller'] == 'critic':
                next_node = 'verification'
            elif self.copy_state['caller'] == 'verification':
                next_node = 'verification'
            # elif self.copy_state['caller'] == 'user':
            #     next_node = 'user',
            else:
                return None
        logger.info(f'coding -> {next_node}')
        return DirectionRouter.goto(state=self.copy_state, node=next_node, method='command')

    @override
    def _prepare_chat_template(self, human_template, *args, **kwargs):
        return ChatPromptTemplate([
            self.system_template,
            human_template,
        ])

    def _generate_script(self, state):
        chat_template = self._prepare_chat_template(self.human_generate_template)

        # that's called only when coding_task is 'generate', when queries are subtasks
        query = state['queries'][self.copy_state['query_offset']]
        docs = state['retrieved_docs'][self.copy_state['query_offset']]
        # -----------precess docs -----------
        #
        # ----------------------------------
        formatted_prompt = chat_template.invoke({
            "subtask": query,
            "previous_scripts": self.copy_state['previous_scripts'],
            "docs": docs,
        })
        # ---------------------------------------------------
        script = self._generate(formatted_prompt)
        # ---------------------------------------------------

        return script

    def _fix_error(self, state) -> str:
        chat_template = self._prepare_chat_template(self.human_fix_template)

        formatted_prompt = chat_template.invoke({
            'script': state['current_script'],
            'error': state['queries'],
            'docs': state['retrieved_docs']
        })

        # ---------------------------------------------------
        fixed_script = self._generate(formatted_prompt)
        # ---------------------------------------------------

        return fixed_script

    def _apply_improvements(self, state):
        chat_template = self._prepare_chat_template(self.human_improve_template)

        formatted_prompt = chat_template.invoke({
            'script': state['current_script'],
            'solution': state['queries'],
            'docs': state['retrieved_docs'],
        })
        # ---------------------------------------------------
        improved_script = self._generate(formatted_prompt)
        # ---------------------------------------------------
        return improved_script

    def _generate(self, formatted_prompt):
        while True:
            # ----------------------------------
            generated_script = self.anchor_call(formatted_prompt)
            # ----------------------------------

            anchor_file = os.path.join(self.anchor_folder, f"fake_script.py")
            """Anchor file to check error"""
            write_script.invoke({
                "script": generated_script,
                "file_path": anchor_file
            })
            result = execute_script.invoke(input={"script": anchor_file})
            error = result['error']

            if len(error) == 0:
                return generated_script
            if self.fix_error_tries == self.fix_error_attempts:
                # Test script would be fixed successfully
                generated_script = 'import sys'
                return generated_script
            else:
                raise ScriptWithError(command=DirectionRouter.goto(state={
                    'current_script': generated_script,
                    'coding_task': 'fix',
                    'queries': [error, ],
                }, node='retriever', method='command')
                )

    @override
    def anchor_call(self, formatted_prompt, *args):
        with open("assets/blender_script/anchor_4.py", 'r') as f:
            return f.read()

    @override
    def chat_model_call(self, formatted_prompt, context):
        response = self.chat_model.invoke(formatted_prompt)
        try:
            generated_script = response.tool_calls[-1]['args']['script']
        except KeyError as e:
            exit()

        return generated_script
